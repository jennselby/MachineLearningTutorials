{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py under the following license:\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2017 Erik Linder-NorÃ©n\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author's model was based on the paper here: https://arxiv.org/pdf/1511.06434.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "images_dir = \"dcgan_images\"\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "noise_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for creating, training, and using the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    '''\n",
    "    Put together a CNN that will return a single confidence output.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    '''\n",
    "    Put together a model that takes in one-dimensional noise and outputs two-dimensional data representing a black\n",
    "    and white image, with -1 for black and 1 for white.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    noise_shape = (noise_len,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined():\n",
    "    '''\n",
    "    Puts together a model that combines the discriminator and generator models.\n",
    "    \n",
    "    returns: the generator, discriminator, and combined model objects\n",
    "    '''\n",
    "    \n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(noise_len,))\n",
    "    img = generator(noise)\n",
    "    \n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(generator, epoch):\n",
    "    '''\n",
    "    Has the generator create images and saves the images in a single file that includes the epoch in the filename.\n",
    "    \n",
    "    inputs:\n",
    "        generator: the generator model object returned by build_combined\n",
    "        epoch: the epoch number (but can be anything that can be represented as a string)\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, noise_len))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "    '''\n",
    "    Trains all model objects\n",
    "    \n",
    "    generator: the generator model object returned by build_combined\n",
    "    discriminator: the discriminator model object returned by build_combined\n",
    "    combined: the combined model object returned by build_combined\n",
    "    epochs: integer, the number of epochs to train for\n",
    "    batch_size: integer, the number of training samples to use at a time\n",
    "    save_interval: integer, will generate and save images when the current epoch % save_interval is 0\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, noise_len))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, noise_len))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # If at save interval => save generated image samples and plot progress\n",
    "        if epoch % save_interval == 0:\n",
    "            # Plot the progress\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print (\"{} [D loss: {}, acc.: {:.2%}] [G loss: {}]\".format(epoch, d_loss[0], d_loss[1], g_loss))\n",
    "            save_imgs(generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_new_image(generator):\n",
    "    '''\n",
    "    Generates and displays a new image\n",
    "    \n",
    "    inputs: generator object model returned from build_combined\n",
    "    \n",
    "    returns: generated image\n",
    "    '''\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (1, noise_len))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the main section of the code, that actually creates the model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directories to hold the images that are saved during training checkpoints.\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(images_dir)):\n",
    "    os.mkdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to build your own new models\n",
    "#generator, discriminator, combined = build_combined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure that you have downloaded the three h5 files before running the next block.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model files. Comment out (or don't run) this block if you want to start with fresh models.\n",
    "from keras.models import load_model\n",
    "\n",
    "generator = load_model('generator.h5')\n",
    "discriminator = load_model('discriminator.h5')\n",
    "combined = load_model('combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.00011625385377556086, acc.: 100.00%] [G loss: 1.991836506931577e-05]\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, combined, epochs=1, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1209cd860>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKCY/UVBMfqKg/g/Hqfu1BIaoZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4670b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')\n",
    "combined.save('combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
