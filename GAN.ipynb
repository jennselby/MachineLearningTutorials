{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "images_dir = \"dcgan_images\"\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined():\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(100,))\n",
    "    img = generator(noise)\n",
    "\n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(generator, epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_new_image(generator):\n",
    "    noise = np.random.normal(0, 1, (1, 100))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directories\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(images_dir)):\n",
    "    os.mkdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 392,705\n",
      "Trainable params: 392,321\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator, discriminator, combined = build_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.803232, acc.: 50.00%] [G loss: 0.722383]\n",
      "1 [D loss: 0.859030, acc.: 56.25%] [G loss: 0.706437]\n",
      "2 [D loss: 0.666880, acc.: 62.50%] [G loss: 0.873928]\n",
      "3 [D loss: 0.515545, acc.: 65.62%] [G loss: 0.992441]\n",
      "4 [D loss: 0.514002, acc.: 75.00%] [G loss: 1.059196]\n",
      "5 [D loss: 0.410517, acc.: 81.25%] [G loss: 1.175979]\n",
      "6 [D loss: 0.407949, acc.: 81.25%] [G loss: 1.124808]\n",
      "7 [D loss: 0.321313, acc.: 90.62%] [G loss: 1.031747]\n",
      "8 [D loss: 0.276462, acc.: 100.00%] [G loss: 1.073001]\n",
      "9 [D loss: 0.256744, acc.: 93.75%] [G loss: 0.837645]\n",
      "10 [D loss: 0.333687, acc.: 84.38%] [G loss: 0.819513]\n",
      "11 [D loss: 0.253069, acc.: 87.50%] [G loss: 0.575317]\n",
      "12 [D loss: 0.219697, acc.: 90.62%] [G loss: 0.372133]\n",
      "13 [D loss: 0.129296, acc.: 100.00%] [G loss: 0.323284]\n",
      "14 [D loss: 0.180972, acc.: 96.88%] [G loss: 0.195894]\n",
      "15 [D loss: 0.194287, acc.: 93.75%] [G loss: 0.150580]\n",
      "16 [D loss: 0.185919, acc.: 93.75%] [G loss: 0.170849]\n",
      "17 [D loss: 0.149987, acc.: 96.88%] [G loss: 0.096591]\n",
      "18 [D loss: 0.264366, acc.: 90.62%] [G loss: 0.109997]\n",
      "19 [D loss: 0.445489, acc.: 68.75%] [G loss: 0.114780]\n",
      "20 [D loss: 0.610301, acc.: 65.62%] [G loss: 0.099493]\n",
      "21 [D loss: 0.480497, acc.: 71.88%] [G loss: 0.175024]\n",
      "22 [D loss: 1.058222, acc.: 56.25%] [G loss: 0.305286]\n",
      "23 [D loss: 0.959620, acc.: 46.88%] [G loss: 0.419074]\n",
      "24 [D loss: 1.102677, acc.: 37.50%] [G loss: 0.632449]\n",
      "25 [D loss: 0.973412, acc.: 37.50%] [G loss: 0.972193]\n",
      "26 [D loss: 0.735223, acc.: 59.38%] [G loss: 1.021358]\n",
      "27 [D loss: 0.763901, acc.: 59.38%] [G loss: 1.066005]\n",
      "28 [D loss: 0.796913, acc.: 43.75%] [G loss: 1.112970]\n",
      "29 [D loss: 0.602804, acc.: 71.88%] [G loss: 1.295913]\n",
      "30 [D loss: 0.776350, acc.: 56.25%] [G loss: 1.557985]\n",
      "31 [D loss: 0.602036, acc.: 65.62%] [G loss: 1.216440]\n",
      "32 [D loss: 0.746960, acc.: 50.00%] [G loss: 1.599284]\n",
      "33 [D loss: 0.476416, acc.: 78.12%] [G loss: 1.670682]\n",
      "34 [D loss: 0.588948, acc.: 68.75%] [G loss: 1.750898]\n",
      "35 [D loss: 0.253945, acc.: 96.88%] [G loss: 1.718327]\n",
      "36 [D loss: 0.501180, acc.: 75.00%] [G loss: 1.597737]\n",
      "37 [D loss: 0.317167, acc.: 81.25%] [G loss: 2.008443]\n",
      "38 [D loss: 0.263107, acc.: 93.75%] [G loss: 2.005672]\n",
      "39 [D loss: 0.327732, acc.: 84.38%] [G loss: 2.086618]\n",
      "40 [D loss: 0.226501, acc.: 93.75%] [G loss: 1.701343]\n",
      "41 [D loss: 0.277300, acc.: 90.62%] [G loss: 1.906256]\n",
      "42 [D loss: 0.261085, acc.: 93.75%] [G loss: 2.242318]\n",
      "43 [D loss: 0.270712, acc.: 93.75%] [G loss: 2.765618]\n",
      "44 [D loss: 0.279303, acc.: 93.75%] [G loss: 2.528296]\n",
      "45 [D loss: 0.245148, acc.: 87.50%] [G loss: 2.663147]\n",
      "46 [D loss: 0.198373, acc.: 93.75%] [G loss: 2.729984]\n",
      "47 [D loss: 0.169521, acc.: 93.75%] [G loss: 2.276083]\n",
      "48 [D loss: 0.186860, acc.: 96.88%] [G loss: 2.777277]\n",
      "49 [D loss: 0.101165, acc.: 100.00%] [G loss: 2.777480]\n",
      "50 [D loss: 0.167366, acc.: 93.75%] [G loss: 2.700193]\n",
      "51 [D loss: 0.139675, acc.: 96.88%] [G loss: 2.887282]\n",
      "52 [D loss: 0.121628, acc.: 96.88%] [G loss: 2.991000]\n",
      "53 [D loss: 0.125219, acc.: 96.88%] [G loss: 3.064468]\n",
      "54 [D loss: 0.150061, acc.: 96.88%] [G loss: 3.363164]\n",
      "55 [D loss: 0.099443, acc.: 100.00%] [G loss: 3.376230]\n",
      "56 [D loss: 0.173834, acc.: 90.62%] [G loss: 2.664091]\n",
      "57 [D loss: 0.363333, acc.: 81.25%] [G loss: 2.147055]\n",
      "58 [D loss: 0.084066, acc.: 100.00%] [G loss: 2.615998]\n",
      "59 [D loss: 0.269199, acc.: 93.75%] [G loss: 3.070059]\n",
      "60 [D loss: 0.077969, acc.: 100.00%] [G loss: 3.325774]\n",
      "61 [D loss: 0.141885, acc.: 96.88%] [G loss: 2.776082]\n",
      "62 [D loss: 0.159468, acc.: 93.75%] [G loss: 2.761757]\n",
      "63 [D loss: 0.111824, acc.: 96.88%] [G loss: 2.659920]\n",
      "64 [D loss: 0.114732, acc.: 96.88%] [G loss: 2.938431]\n",
      "65 [D loss: 0.081525, acc.: 100.00%] [G loss: 3.026894]\n",
      "66 [D loss: 0.117485, acc.: 96.88%] [G loss: 3.170985]\n",
      "67 [D loss: 0.104850, acc.: 100.00%] [G loss: 2.976916]\n",
      "68 [D loss: 0.105640, acc.: 100.00%] [G loss: 3.242829]\n",
      "69 [D loss: 0.213699, acc.: 96.88%] [G loss: 2.263652]\n",
      "70 [D loss: 0.323661, acc.: 87.50%] [G loss: 2.067167]\n",
      "71 [D loss: 0.127893, acc.: 96.88%] [G loss: 2.281235]\n",
      "72 [D loss: 0.141651, acc.: 100.00%] [G loss: 3.135119]\n",
      "73 [D loss: 0.083472, acc.: 100.00%] [G loss: 3.703256]\n",
      "74 [D loss: 0.269834, acc.: 93.75%] [G loss: 2.793768]\n",
      "75 [D loss: 0.096374, acc.: 100.00%] [G loss: 2.457833]\n",
      "76 [D loss: 0.368040, acc.: 81.25%] [G loss: 2.301404]\n",
      "77 [D loss: 0.302920, acc.: 90.62%] [G loss: 3.628846]\n",
      "78 [D loss: 0.292502, acc.: 87.50%] [G loss: 2.597697]\n",
      "79 [D loss: 0.367082, acc.: 81.25%] [G loss: 1.937819]\n",
      "80 [D loss: 0.250997, acc.: 93.75%] [G loss: 3.403649]\n",
      "81 [D loss: 0.060258, acc.: 100.00%] [G loss: 3.602571]\n",
      "82 [D loss: 0.077567, acc.: 100.00%] [G loss: 3.837193]\n",
      "83 [D loss: 0.287535, acc.: 84.38%] [G loss: 1.745408]\n",
      "84 [D loss: 0.560919, acc.: 68.75%] [G loss: 2.416949]\n",
      "85 [D loss: 0.080228, acc.: 100.00%] [G loss: 3.146606]\n",
      "86 [D loss: 0.286794, acc.: 90.62%] [G loss: 2.821175]\n",
      "87 [D loss: 0.187091, acc.: 96.88%] [G loss: 2.385838]\n",
      "88 [D loss: 0.220809, acc.: 90.62%] [G loss: 2.803479]\n",
      "89 [D loss: 0.267989, acc.: 90.62%] [G loss: 2.533790]\n",
      "90 [D loss: 0.395293, acc.: 81.25%] [G loss: 2.386522]\n",
      "91 [D loss: 0.170030, acc.: 100.00%] [G loss: 2.805323]\n",
      "92 [D loss: 0.447746, acc.: 75.00%] [G loss: 3.324057]\n",
      "93 [D loss: 0.605104, acc.: 65.62%] [G loss: 2.717932]\n",
      "94 [D loss: 0.839389, acc.: 50.00%] [G loss: 3.696835]\n",
      "95 [D loss: 0.589097, acc.: 71.88%] [G loss: 2.448425]\n",
      "96 [D loss: 0.605758, acc.: 65.62%] [G loss: 2.981419]\n",
      "97 [D loss: 0.519269, acc.: 68.75%] [G loss: 3.039020]\n",
      "98 [D loss: 0.458906, acc.: 84.38%] [G loss: 2.806741]\n",
      "99 [D loss: 0.835260, acc.: 56.25%] [G loss: 2.353868]\n",
      "100 [D loss: 0.746386, acc.: 62.50%] [G loss: 3.338425]\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, combined, epochs=101, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first images:\n",
    "![](dcgan_images/mnist_0.png)\n",
    "The last images (epoch 100):\n",
    "![](dcgan_images/mnist_100.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119718588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1195b0320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
