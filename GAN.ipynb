{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "images_dir = \"dcgan_images\"\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined():\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(100,))\n",
    "    img = generator(noise)\n",
    "\n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(generator, epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_new_image(generator):\n",
    "    noise = np.random.normal(0, 1, (1, 100))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directories\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(images_dir)):\n",
    "    os.mkdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator, combined = build_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.876758, acc.: 37.50%] [G loss: 0.735169]\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, combined, epochs=1, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first images:\n",
    "![](dcgan_images/mnist_0.png)\n",
    "The last images (epoch 100):\n",
    "![](dcgan_images/mnist_100.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x118893940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKH6gUxQ/0CmKH+gUxQ906v8B2wbrbpsQdqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a62cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
