{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "images_dir = \"dcgan_images\"\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "noise_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (noise_len,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined():\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(noise_len,))\n",
    "    img = generator(noise)\n",
    "\n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(generator, epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, noise_len))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, noise_len))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, noise_len))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_new_image(generator):\n",
    "    noise = np.random.normal(0, 1, (1, noise_len))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directories\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(images_dir)):\n",
    "    os.mkdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator, combined = build_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.953769, acc.: 40.62%] [G loss: 0.567848]\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, combined, epochs=1, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first images:\n",
    "![](dcgan_images/mnist_0.png)\n",
    "The last images (epoch 100):\n",
    "![](dcgan_images/mnist_100.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1194c8898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6BTFD3SK4gc6RfEDnaL4gU5R/ECn/h8F/k3qmqoiOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d352e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
